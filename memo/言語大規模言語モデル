**米Metaは5月22日（現地時間）、4000以上の音声言語を識別できる多言語大規模言語モデル「Massively Multilingual Speech」（MMS）のモデルとを研究コミュニティにオープンソースで公開したと発表した。**
-MMSプロジェクトでは、自己教師あり学習モデルの「wav2vec 2.0」、1100以上のラベル付き言語データ、約4000のラベルなし言語データのデータセットを使ってモデルを構築したという。
-4000以上の音声言語識別は既存技術の40倍の能力だとしている。



-「われわれの目標は、人々が好きな言語で情報に簡単にアクセスできるようにすること」で、
-「VRやAR、メッセージングサービスに至るまで、多様なサービスで人々が自分の母国語を使いつつ周囲の声を理解できるようになる」と語った。

-つまり、メタバースでの自由な交流もMMSの目的の1つということだろう。

